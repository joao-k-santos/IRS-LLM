# Agente LLM para o Sistema de Preven√ß√£o de Intrus√£o Baseado em Host
Construido em Docker, Python (FastAPI) e Ollama

# Como construir:
No diret√≥rio onde foi feito o clone do reposit√≥rio do github
```sh
cd ./SPIH/llm-agent
docker-compose build
docker-compose up -d
```

# Para interromper a execu√ß√£o
```sh
docker-compose down
```

# Informa√ß√µes de Rede
A API fica exposta na porta 8000 no localhost
http://localhost:8000

O servidor Ollama fica exposto, fora do Docker, na porta 11444 no localhost
http://localhost:11444

# Para usar o bash de cada Container
```sh
docker exec -it api_llm bash
docker exec -it ollama bash
```

Ou

```sh
docker exec -it api_llm sh
docker exec -it ollama sh
```

üìå Endpoints
1. Registrar Ataque

Adiciona um ataque detectado ao banco de dados.

    Endpoint

```http
POST /registrar_ataque
```
```json
Par√¢metros (JSON)

{
  "tipo": "DoS",
  "descricao": "Ataque de nega√ß√£o de servi√ßo",
  "detalhes": "V√°rios pacotes ICMP"
}
```
```http

```
```json

```
```json
Resposta

    {
      "mensagem": "Ataque registrado com sucesso!"
    }
```


2. Listar Ataques

Lista todos os ataques registrados no banco de dados.

    Endpoint

```http
GET /listar_ataques
```

```json
Resposta

    [
      {
        "id": 1,
        "tipo": "DoS",
        "descricao": "Ataque de nega√ß√£o de servi√ßo",
        "detalhes": "V√°rios pacotes ICMP"
      },
      {
        "id": 2,
        "tipo": "Botnet",
        "descricao": "Ataque distribu√≠do com m√∫ltiplos bots",
        "detalhes": "Uso de Mirai botnet"
      }
    ]
```


3. Baixar Modelo

Solicita ao Ollama o download de um modelo espec√≠fico.

    Endpoint

```http
POST /download_model/
```

```json
Par√¢metros (JSON)

{
  "model_name": "llama3.2:3b"
}

Resposta

    {
      "message": "Modelo llama3.2:3b baixado com sucesso"
    }
```


4. Gerar Regras de Seguran√ßa

Gera regras de seguran√ßa baseadas nos ataques registrados no banco de dados.

    Endpoint

GET /gerar_regras

Par√¢metros (Query)
Nome	Tipo	Obrigat√≥rio	Descri√ß√£o
model	string	N√£o	Nome do modelo a ser usado (padr√£o: llama3.2:3b)

Resposta

    {
      "firewall": [
        "iptables -A INPUT -s 192.168.0.0/24 -j DROP"
      ],
      "ids": [
        "alert tcp any any -> any 80 (msg:\"Suspicious HTTP request\"; sid:1000001;)"
      ],
      "ips": [
        "fail2ban action: ban IP 192.168.1.1"
      ]
    }

5. Listar Modelos Dispon√≠veis

Lista todos os modelos dispon√≠veis no servidor Ollama.

    Endpoint

GET /models

Resposta

    [
      {
        "name": "llama3.2:3b",
        "tags": ["llama", "3b"]
      },
      {
        "name": "gpt4:large",
        "tags": ["gpt", "large"]
      }
    ]

6. Gerar Resposta

Gera uma resposta do modelo especificado com base no prompt fornecido.

    Endpoint

POST /generate/

Par√¢metros (JSON)

{
  "model": "llama3.2:3b",
  "prompt": "Como mitigar ataques DoS?"
}

Resposta

    {
      "regras": "Para mitigar ataques DoS, recomenda-se utilizar t√©cnicas de rate-limiting e bloquear IPs suspeitos."
    }

üõë Erros Comuns e Solu√ß√µes
‚ùå Erro ao Registrar Ataque

    Descri√ß√£o: A requisi√ß√£o falhou ao tentar registrar um ataque.

    Solu√ß√£o: Verifique se os par√¢metros tipo, descricao e detalhes est√£o sendo enviados corretamente.

‚ùå Erro ao Baixar Modelo

    Descri√ß√£o: N√£o foi poss√≠vel baixar o modelo do Ollama.

    Solu√ß√£o: Certifique-se de que o servidor Ollama est√° rodando e que o nome do modelo est√° correto.

‚ùå Erro ao Gerar Regras

    Descri√ß√£o: O processamento das regras falhou ao tentar gerar as regras com base nos ataques registrados.

    Solu√ß√£o: Verifique se h√° ataques registrados e se o servidor Ollama est√° operacional.
